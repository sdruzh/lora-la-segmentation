# LoRA-LA: Low-Rank Atom Distillation for Efficient Segmentation

This repository contains the code, training logs, and results for our paper:

**"Efficient Student Segmentation: Reducing Linear Layer Computations with Near-Teacher Accuracy"**  
_Aleksandr Druzhinin, 2025_  

ðŸ“„ Preprint: [arXiv link (coming soon)](https://arxiv.org)  
ðŸ“‚ Checkpoints and logs: [Google Drive](https://drive.google.com/drive/folders/1Eotm6cXJR0BU6kmUFpOaJP4Tn5lkPoGW?usp=drive_link)  

---

## ðŸ”¥ Highlights
- **Teacher**: SegFormer-B0 for binary human segmentation.  
- **Student**: trained with **LoRA-LA (Low-Rank Atom + Delayed Sparsity + KR-hard + EMA)**.  
- **Results**:  
  - Teacher: **0.9366 mIoU**  
  - Student Phase-1: **0.9115 mIoU** (best at epoch 10, 23 epochs total)  
  - Student Phase-2: **0.9364 mIoU** (best at epoch 12, 15 epochs total)  
- **Efficiency**: linear FLOPs reduced by **~5Ã—**, while maintaining **teacher-level accuracy**.  

---

## ðŸ“Š Training Curves
<p align="center">
  <img src="phase1_curve.png" alt="Phase-1 curve" width="45%"/>
  <img src="phase2_curve.png" alt="Phase-2 curve" width="45%"/>
</p>

---

## ðŸ“‚ Repository Structure
- `article0_run.ipynb` â€” training notebook with all logs.  
- `phase1_curve.png`, `phase2_curve.png` â€” training curves.  
- `phase1_curve.csv`, `phase2_curve.csv` â€” extracted metrics.  
- `README.md` â€” project description.  
- (optional) `requirements.txt` â€” dependencies.  

---

## ðŸš€ Usage
Clone this repository and open the Jupyter Notebook:

```bash
git clone https://github.com/yourname/lora-la-segmentation.git
cd lora-la-segmentation
jupyter notebook article0_run.ipynb
